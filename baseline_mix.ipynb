{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    " @file   baseline.py\n",
    " @brief  Baseline code of simple AE-based anomaly detection used experiment in [1].\n",
    " @author Ryo Tanabe and Yohei Kawaguchi (Hitachi Ltd.)\n",
    " Copyright (C) 2019 Hitachi, Ltd. All right reserved.\n",
    " [1] Harsh Purohit, Ryo Tanabe, Kenji Ichige, Takashi Endo, Yuki Nikaido, Kaori Suefusa, and Yohei Kawaguchi, \"MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection,\" arXiv preprint arXiv:1909.09347, 2019.\n",
    "\"\"\"\n",
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import numpy\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "import yaml\n",
    "# from import\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import *\n",
    "from model import TorchModel\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# version\n",
    "########################################################################\n",
    "__versions__ = \"1.0.3\"\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# feature extractor\n",
    "########################################################################\n",
    "\n",
    "def list_to_spec_vector_array(file_list,\n",
    "                         msg=\"calc...\",\n",
    "                         n_mels=64,\n",
    "                         frames=5,\n",
    "                         n_fft=1024,\n",
    "                         hop_length=512,\n",
    "                         power=2.0):\n",
    "    \"\"\"\n",
    "    convert the file_list to a vector array.\n",
    "    file_to_vector_array() is iterated, and the output vector array is concatenated.\n",
    "    file_list : list [ str ]\n",
    "        .wav filename list of dataset\n",
    "    msg : str ( default = \"calc...\" )\n",
    "        description for tqdm.\n",
    "        this parameter will be input into \"desc\" param at tqdm.\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        training dataset (when generate the validation data, this function is not used.)\n",
    "        * dataset.shape = (total_dataset_size, feature_vector_length)\n",
    "    \"\"\"\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "\n",
    "    # 02 loop of file_to_vectorarray\n",
    "    for idx in tqdm(range(len(file_list)), desc=msg):\n",
    "\n",
    "        vector_array = file_to_spec_vector_array(file_list[idx],\n",
    "                                            n_mels=n_mels,\n",
    "                                            frames=frames,\n",
    "                                            n_fft=n_fft,\n",
    "                                            hop_length=hop_length,\n",
    "                                            power=power)\n",
    "\n",
    "        if idx == 0:\n",
    "            dataset = numpy.zeros((vector_array.shape[0] * len(file_list), dims), float)\n",
    "\n",
    "        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class AEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "            file_list,\n",
    "            param,\n",
    "            target_source=None,\n",
    "            ):\n",
    "        self.file_list = file_list\n",
    "        self.target_source = target_source\n",
    "\n",
    "        self.data_vector = list_to_spec_vector_array(self.file_list,\n",
    "                                            msg=\"generate train_dataset\",\n",
    "                                            n_mels=param[\"feature\"][\"n_mels\"],\n",
    "                                            frames=param[\"feature\"][\"frames\"],\n",
    "                                            n_fft=param[\"feature\"][\"n_fft\"],\n",
    "                                            hop_length=param[\"feature\"][\"hop_length\"],\n",
    "                                            power=param[\"feature\"][\"power\"],\n",
    "                                            )\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(self.data_vector[index, :])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_vector.shape[0]\n",
    "\n",
    "\n",
    "def dataset_generator(target_dir,\n",
    "                      normal_dir_name=\"normal\",\n",
    "                      abnormal_dir_name=\"abnormal\",\n",
    "                      ext=\"wav\"):\n",
    "    \"\"\"\n",
    "    target_dir : str\n",
    "        base directory path of the dataset\n",
    "    normal_dir_name : str (default=\"normal\")\n",
    "        directory name the normal data located in\n",
    "    abnormal_dir_name : str (default=\"abnormal\")\n",
    "        directory name the abnormal data located in\n",
    "    ext : str (default=\"wav\")\n",
    "        filename extension of audio files \n",
    "    return : \n",
    "        train_data : numpy.array( numpy.array( float ) )\n",
    "            training dataset\n",
    "            * dataset.shape = (total_dataset_size, feature_vector_length)\n",
    "        train_files : list [ str ]\n",
    "            file list for training\n",
    "        train_labels : list [ boolean ] \n",
    "            label info. list for training\n",
    "            * normal/abnormal = 0/1\n",
    "        eval_files : list [ str ]\n",
    "            file list for evaluation\n",
    "        eval_labels : list [ boolean ] \n",
    "            label info. list for evaluation\n",
    "            * normal/abnormal = 0/1\n",
    "    \"\"\"\n",
    "    logger.info(\"target_dir : {}\".format(target_dir))\n",
    "\n",
    "    # 01 normal list generate\n",
    "    normal_files = sorted(glob.glob(\n",
    "        os.path.abspath(\"{dir}/{normal_dir_name}/*.{ext}\".format(dir=target_dir,\n",
    "                                                                 normal_dir_name=normal_dir_name,\n",
    "                                                                 ext=ext))))\n",
    "    normal_labels = numpy.zeros(len(normal_files))\n",
    "    if len(normal_files) == 0:\n",
    "        logger.exception(\"no_wav_data!!\")\n",
    "\n",
    "    # 02 abnormal list generate\n",
    "    abnormal_files = sorted(glob.glob(\n",
    "        os.path.abspath(\"{dir}/{abnormal_dir_name}/*.{ext}\".format(dir=target_dir,\n",
    "                                                                   abnormal_dir_name=abnormal_dir_name,\n",
    "                                                                   ext=ext))))                              \n",
    "    abnormal_labels = numpy.ones(len(abnormal_files))\n",
    "    if len(abnormal_files) == 0:\n",
    "        logger.exception(\"no_wav_data!!\")\n",
    "\n",
    "    # 03 separate train & eval\n",
    "    train_files = normal_files[len(abnormal_files):]\n",
    "    train_labels = normal_labels[len(abnormal_files):]\n",
    "    eval_files = numpy.concatenate((normal_files[:len(abnormal_files)], abnormal_files), axis=0)\n",
    "    eval_labels = numpy.concatenate((normal_labels[:len(abnormal_files)], abnormal_labels), axis=0)\n",
    "    logger.info(\"train_file num : {num}\".format(num=len(train_files)))\n",
    "    logger.info(\"eval_file  num : {num}\".format(num=len(eval_files)))\n",
    "\n",
    "    return train_files, train_labels, eval_files, eval_labels\n",
    "\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest-poscoict/.conda/envs/mtp_0427/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14105/2311920853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# main\n",
    "########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # load parameter yaml\n",
    "    with open(\"baseline.yaml\") as stream:\n",
    "        param = yaml.safe_load(stream)\n",
    "\n",
    "    # make output directory\n",
    "    os.makedirs(param[\"pickle_directory\"], exist_ok=True)\n",
    "    os.makedirs(param[\"model_directory\"], exist_ok=True)\n",
    "    os.makedirs(param[\"result_directory\"], exist_ok=True)\n",
    "\n",
    "    # initialize the visualizer\n",
    "    visualizer = visualizer()\n",
    "\n",
    "    # load base_directory list\n",
    "    dirs = sorted(glob.glob(os.path.abspath(\"{base}/6dB/valve/id_00\".format(base=param[\"base_directory\"]))))\n",
    "\n",
    "    # setup the result\n",
    "    result_file = \"{result}/{file_name}\".format(result=param[\"result_directory\"], file_name=param[\"result_file\"])\n",
    "    results = {}\n",
    "\n",
    "    # loop of the base directory\n",
    "    for dir_idx, target_dir in enumerate(dirs):\n",
    "        print(\"\\n===========================\")\n",
    "        print(\"[{num}/{total}] {dirname}\".format(dirname=target_dir, num=dir_idx + 1, total=len(dirs)))\n",
    "\n",
    "        # dataset param        \n",
    "        db = os.path.split(os.path.split(os.path.split(target_dir)[0])[0])[1]\n",
    "        machine_type = os.path.split(os.path.split(target_dir)[0])[1]\n",
    "        machine_id = os.path.split(target_dir)[1]\n",
    "\n",
    "        # setup path\n",
    "        evaluation_result = {}\n",
    "        train_pickle = \"{pickle}/train_{machine_type}_{machine_id}_{db}.pickle\".format(pickle=param[\"pickle_directory\"],\n",
    "                                                                                       machine_type=machine_type,\n",
    "                                                                                       machine_id=machine_id, db=db)\n",
    "        eval_files_pickle = \"{pickle}/eval_files_{machine_type}_{machine_id}_{db}.pickle\".format(\n",
    "                                                                                       pickle=param[\"pickle_directory\"],\n",
    "                                                                                       machine_type=machine_type,\n",
    "                                                                                       machine_id=machine_id,\n",
    "                                                                                       db=db)\n",
    "        eval_labels_pickle = \"{pickle}/eval_labels_{machine_type}_{machine_id}_{db}.pickle\".format(\n",
    "                                                                                       pickle=param[\"pickle_directory\"],\n",
    "                                                                                       machine_type=machine_type,\n",
    "                                                                                       machine_id=machine_id,\n",
    "                                                                                       db=db)\n",
    "        model_file = \"{model}/model_{machine_type}_{machine_id}_{db}.hdf5\".format(model=param[\"model_directory\"],\n",
    "                                                                                  machine_type=machine_type,\n",
    "                                                                                  machine_id=machine_id,\n",
    "                                                                                  db=db)\n",
    "        history_img = \"{model}/history_{machine_type}_{machine_id}_{db}.png\".format(model=param[\"model_directory\"],\n",
    "                                                                                    machine_type=machine_type,\n",
    "                                                                                    machine_id=machine_id,\n",
    "                                                                                    db=db)\n",
    "        evaluation_result_key = \"{machine_type}_{machine_id}_{db}\".format(machine_type=machine_type,\n",
    "                                                                          machine_id=machine_id,\n",
    "                                                                          db=db)\n",
    "\n",
    "        # dataset generator\n",
    "        print(\"============== DATASET_GENERATOR ==============\")\n",
    "        if os.path.exists(train_pickle) and os.path.exists(eval_files_pickle) and os.path.exists(eval_labels_pickle):\n",
    "            train_files = load_pickle(train_pickle)\n",
    "            eval_files = load_pickle(eval_files_pickle)\n",
    "            eval_labels = load_pickle(eval_labels_pickle)\n",
    "        else:\n",
    "            train_files, train_labels, eval_files, eval_labels = dataset_generator(target_dir)\n",
    "\n",
    "            save_pickle(train_pickle, train_files)\n",
    "            save_pickle(eval_files_pickle, eval_files)\n",
    "            save_pickle(eval_labels_pickle, eval_labels)\n",
    "\n",
    "        train_dataset = AEDataset(train_files, param)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=param[\"fit\"][\"batch_size\"], shuffle=True,\n",
    "        )\n",
    "\n",
    "        # model training\n",
    "        print(\"============== MODEL TRAINING ==============\")\n",
    "        dim_input = train_dataset.data_vector.shape[1]\n",
    "        model = TorchModel(dim_input).cuda()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(param[\"fit\"][\"epochs\"]):\n",
    "            losses = []\n",
    "            for batch in train_loader:\n",
    "                batch = batch.cuda()\n",
    "                pred = model(batch)\n",
    "                loss = loss_fn(pred, batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"epoch {epoch}: loss {sum(losses) / len(losses)}\")\n",
    "        model.eval()\n",
    "\n",
    "        # evaluation\n",
    "        print(\"============== EVALUATION ==============\")\n",
    "        y_pred = [0. for k in eval_labels]\n",
    "        y_true = eval_labels\n",
    "\n",
    "        for num, file_name in tqdm(enumerate(eval_files), total=len(eval_files)):\n",
    "            data = file_to_spec_vector_array(file_name,\n",
    "                                        n_mels=param[\"feature\"][\"n_mels\"],\n",
    "                                        frames=param[\"feature\"][\"frames\"],\n",
    "                                        n_fft=param[\"feature\"][\"n_fft\"],\n",
    "                                        hop_length=param[\"feature\"][\"hop_length\"],\n",
    "                                        power=param[\"feature\"][\"power\"])\n",
    "            data = torch.Tensor(data).cuda()\n",
    "            error = torch.mean(((data - model(data)) ** 2), dim=1)\n",
    "            y_pred[num] = torch.mean(error).detach().cpu().numpy()\n",
    "\n",
    "        score = metrics.roc_auc_score(y_true, y_pred)\n",
    "        logger.info(\"anomaly score abnormal : {}\".format(str(numpy.array(y_pred)[y_true.astype(bool)])))\n",
    "        logger.info(\"anomaly score normal : {}\".format(str(numpy.array(y_pred)[numpy.logical_not(y_true)])))\n",
    "        logger.info(\"AUC : {}\".format(score))\n",
    "        evaluation_result[\"AUC\"] = float(score)\n",
    "        results[evaluation_result_key] = evaluation_result\n",
    "        print(\"===========================\")\n",
    "\n",
    "    # output results\n",
    "    print(\"\\n===========================\")\n",
    "    logger.info(\"all results -> {}\".format(result_file))\n",
    "    with open(result_file, \"w\") as f:\n",
    "        f.write(yaml.dump(results, default_flow_style=False))\n",
    "    print(\"===========================\")\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./baseline.py\", line 184, in <module>\n",
      "    with open(\"baseline.yaml\") as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'baseline.yaml'\n"
     ]
    }
   ],
   "source": [
    "!python ./baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomaly.utils import bandwidth_to_max_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtp_0427",
   "language": "python",
   "name": "mtp_0427"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
